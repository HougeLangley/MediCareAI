"""
Unified Knowledge Base Service
ç»Ÿä¸€çŸ¥è¯†åº“æœåŠ¡ - æ”¯æŒæ‰å¹³åŒ–çŸ¥è¯†åº“ç»“æ„

æ–°æ¶æ„ï¼šæ‰€æœ‰æ–‡æ¡£ç»Ÿä¸€å­˜æ”¾åœ¨ unified/ ç›®å½•ä¸‹ï¼Œä¸å†æŒ‰ç–¾ç—…åˆ†ç±»
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class UnifiedDocument:
    """ç»Ÿä¸€çŸ¥è¯†åº“æ–‡æ¡£"""
    filename: str
    title: str
    category: str
    tags: List[str] = field(default_factory=list)
    source: str = ""
    content: str = ""
    file_path: Path = None
    file_size: int = 0
    last_modified: datetime = None


class UnifiedKnowledgeLoader:
    """
    ç»Ÿä¸€çŸ¥è¯†åº“åŠ è½½å™¨ (Unified Knowledge Base Loader)
    
    ç‰¹ç‚¹ï¼š
    - æ‰€æœ‰æ–‡æ¡£å­˜æ”¾åœ¨ unified/ ç›®å½•ä¸‹
    - é€šè¿‡ metadata.json ç®¡ç†æ–‡æ¡£å…ƒæ•°æ®
    - æ”¯æŒåŠ¨æ€æ‰«æç›®å½•è‡ªåŠ¨å‘ç°æ–°æ–‡æ¡£
    - ä¸å†æŒ‰ç–¾ç—…åˆ†ç±»ï¼Œå®Œå…¨æ‰å¹³åŒ–
    """
    
    def __init__(self, kb_root: str = "/app/data/knowledge_bases"):
        self.kb_root = Path(kb_root)
        self.unified_root = self.kb_root / "unified"
        self.metadata_file = self.unified_root / "metadata.json"
        self._cache: Dict[str, UnifiedDocument] = {}
        self._metadata: Dict = {}
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.unified_root.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½æˆ–åˆ›å»ºå…ƒæ•°æ®
        self._load_or_create_metadata()
    
    def _load_or_create_metadata(self):
        """åŠ è½½æˆ–åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self._metadata = json.load(f)
                logger.info(f"âœ… åŠ è½½ç»Ÿä¸€çŸ¥è¯†åº“å…ƒæ•°æ®: {len(self._metadata.get('documents', []))} ä¸ªæ–‡æ¡£")
            except Exception as e:
                logger.error(f"âŒ åŠ è½½å…ƒæ•°æ®å¤±è´¥: {e}")
                self._create_default_metadata()
        else:
            self._create_default_metadata()
    
    def _create_default_metadata(self):
        """åˆ›å»ºé»˜è®¤å…ƒæ•°æ®"""
        self._metadata = {
            "name": "ç»Ÿä¸€åŒ»å­¦çŸ¥è¯†åº“",
            "name_en": "Unified Medical Knowledge Base",
            "description": "åŒ…å«æ‰€æœ‰åŒ»å­¦é¢†åŸŸçš„è¯Šç–—æŒ‡å—å’ŒçŸ¥è¯†æ–‡æ¡£",
            "version": "2.0.0",
            "structure": "unified",
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "documents": [],
            "stats": {
                "total_documents": 0,
                "categories": []
            }
        }
        self._save_metadata()
    
    def _save_metadata(self):
        """ä¿å­˜å…ƒæ•°æ®åˆ°æ–‡ä»¶"""
        try:
            self._metadata['updated_at'] = datetime.now().isoformat()
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self._metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")
    
    def scan_and_update_metadata(self) -> Dict[str, Any]:
        """
        æ‰«æç›®å½•å¹¶æ›´æ–°å…ƒæ•°æ®
        è‡ªåŠ¨å‘ç°æ–°æ·»åŠ çš„æ–‡æ¡£
        """
        discovered_docs = []
        categories = set()
        
        # æ‰«ææ‰€æœ‰ .md æ–‡ä»¶
        for md_file in self.unified_root.glob("*.md"):
            filename = md_file.name
            
            # æ£€æŸ¥æ˜¯å¦å·²åœ¨å…ƒæ•°æ®ä¸­
            existing = next(
                (d for d in self._metadata.get('documents', []) if d['filename'] == filename),
                None
            )
            
            if existing:
                # æ›´æ–°æ–‡ä»¶ä¿¡æ¯
                existing['file_size'] = md_file.stat().st_size
                discovered_docs.append(existing)
                categories.add(existing.get('category', 'uncategorized'))
            else:
                # æ–°æ–‡æ¡£ - è‡ªåŠ¨æå–ä¿¡æ¯
                try:
                    content = md_file.read_text(encoding='utf-8')[:500]  # è¯»å–å‰500å­—ç¬¦
                    
                    # å°è¯•ä»å†…å®¹æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰
                    title = content.split('\n')[0].replace('#', '').strip()
                    if not title:
                        title = filename.replace('.md', '')
                    
                    # è‡ªåŠ¨æ¨æ–­åˆ†ç±»ï¼ˆä»æ–‡ä»¶åæˆ–å†…å®¹ï¼‰
                    category = self._infer_category(filename, content)
                    categories.add(category)
                    
                    new_doc = {
                        "filename": filename,
                        "title": title,
                        "category": category,
                        "tags": self._extract_tags(filename, content),
                        "source": "",
                        "file_size": md_file.stat().st_size,
                        "added_at": datetime.now().isoformat()
                    }
                    discovered_docs.append(new_doc)
                    logger.info(f"ğŸ“„ å‘ç°æ–°æ–‡æ¡£: {filename} (åˆ†ç±»: {category})")
                    
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†æ–‡æ¡£å¤±è´¥ {filename}: {e}")
        
        # æ›´æ–°å…ƒæ•°æ®
        self._metadata['documents'] = discovered_docs
        self._metadata['stats'] = {
            "total_documents": len(discovered_docs),
            "categories": list(categories),
            "last_scan": datetime.now().isoformat()
        }
        self._save_metadata()
        
        logger.info(f"âœ… æ‰«æå®Œæˆ: {len(discovered_docs)} ä¸ªæ–‡æ¡£, {len(categories)} ä¸ªåˆ†ç±»")
        return self._metadata['stats']
    
    def _infer_category(self, filename: str, content: str) -> str:
        """
        åˆ†ç±»æ¨æ–­ - ç»Ÿä¸€ä½¿ç”¨ 'unified'
        
        ä¸ºäº†ç®€åŒ–çŸ¥è¯†åº“ç»“æ„ï¼Œæ‰€æœ‰æ–‡æ¡£ç»Ÿä¸€å½’ç±»ä¸º 'unified'ï¼Œ
        ä¸å†æŒ‰ç–¾ç—…ç±»å‹ç»†åˆ†ã€‚åˆ†ç±»ä¿¡æ¯ä»…ç”¨äºæ ‡è¯†ï¼Œä¸å½±å“æ£€ç´¢é€»è¾‘ã€‚
        """
        # ç»Ÿä¸€ä½¿ç”¨ 'unified' åˆ†ç±»ï¼Œä¸å†æ¨æ–­å…·ä½“ç–¾ç—…åˆ†ç±»
        return 'unified'
    
    def _extract_tags(self, filename: str, content: str) -> List[str]:
        """ä»æ–‡ä»¶åå’Œå†…å®¹æå–æ ‡ç­¾"""
        tags = []
        text = (filename + ' ' + content[:500]).lower()
        
        tag_keywords = {
            'æŒ‡å—': ['æŒ‡å—', 'guideline', 'è¯Šç–—'],
            'è§„èŒƒ': ['è§„èŒƒ', 'standard', 'è§„èŒƒåŒ–'],
            'å„¿ç«¥': ['å„¿ç«¥', 'å°å„¿', 'pediatric', 'children'],
            'æ€¥æ€§': ['æ€¥æ€§', 'acute'],
            'æ…¢æ€§': ['æ…¢æ€§', 'chronic'],
            'è¯Šæ–­': ['è¯Šæ–­', 'diagnosis', 'è¯Šæ–­æ ‡å‡†'],
            'æ²»ç–—': ['æ²»ç–—', 'therapy', 'treatment', 'è¯ç‰©']
        }
        
        for tag, keywords in tag_keywords.items():
            if any(kw in text for kw in keywords):
                tags.append(tag)
        
        return tags[:5]  # æœ€å¤š5ä¸ªæ ‡ç­¾
    
    def list_documents(self, category: str = None) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£"""
        docs = self._metadata.get('documents', [])
        
        if category:
            docs = [d for d in docs if d.get('category') == category]
        
        return docs
    
    def load_document(self, filename: str) -> Optional[UnifiedDocument]:
        """åŠ è½½æŒ‡å®šæ–‡æ¡£å†…å®¹"""
        # æ£€æŸ¥ç¼“å­˜
        if filename in self._cache:
            return self._cache[filename]
        
        # æŸ¥æ‰¾æ–‡æ¡£
        doc_meta = next(
            (d for d in self._metadata.get('documents', []) if d['filename'] == filename),
            None
        )
        
        if not doc_meta:
            return None
        
        file_path = self.unified_root / filename
        if not file_path.exists():
            return None
        
        try:
            content = file_path.read_text(encoding='utf-8')
            stat = file_path.stat()
            
            doc = UnifiedDocument(
                filename=filename,
                title=doc_meta.get('title', filename),
                category=doc_meta.get('category', 'general'),
                tags=doc_meta.get('tags', []),
                source=doc_meta.get('source', ''),
                content=content,
                file_path=file_path,
                file_size=stat.st_size,
                last_modified=datetime.fromtimestamp(stat.st_mtime)
            )
            
            # ç¼“å­˜
            self._cache[filename] = doc
            return doc
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ–‡æ¡£å¤±è´¥ {filename}: {e}")
            return None
    
    def load_all_documents(self) -> List[UnifiedDocument]:
        """åŠ è½½æ‰€æœ‰æ–‡æ¡£"""
        docs = []
        for doc_meta in self._metadata.get('documents', []):
            doc = self.load_document(doc_meta['filename'])
            if doc:
                docs.append(doc)
        return docs
    
    def add_document(self, filename: str, content: str, 
                     title: str = None, category: str = None,
                     tags: List[str] = None, source: str = "") -> bool:
        """
        æ·»åŠ æ–°æ–‡æ¡£åˆ°çŸ¥è¯†åº“
        """
        try:
            file_path = self.unified_root / filename
            
            # å†™å…¥æ–‡ä»¶
            file_path.write_text(content, encoding='utf-8')
            
            # æ¨æ–­å…ƒæ•°æ®
            if not title:
                title = filename.replace('.md', '')
            if not category:
                category = self._infer_category(filename, content)
            if not tags:
                tags = self._extract_tags(filename, content)
            
            # æ·»åŠ åˆ°å…ƒæ•°æ®
            new_doc = {
                "filename": filename,
                "title": title,
                "category": category,
                "tags": tags,
                "source": source,
                "file_size": len(content.encode('utf-8')),
                "added_at": datetime.now().isoformat()
            }
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing_idx = next(
                (i for i, d in enumerate(self._metadata['documents']) 
                 if d['filename'] == filename),
                None
            )
            
            if existing_idx is not None:
                self._metadata['documents'][existing_idx] = new_doc
            else:
                self._metadata['documents'].append(new_doc)
            
            # æ›´æ–°ç»Ÿè®¡
            categories = set(d.get('category', 'general') for d in self._metadata['documents'])
            self._metadata['stats'] = {
                "total_documents": len(self._metadata['documents']),
                "categories": list(categories),
                "last_updated": datetime.now().isoformat()
            }
            
            self._save_metadata()
            
            # æ¸…é™¤ç¼“å­˜
            if filename in self._cache:
                del self._cache[filename]
            
            logger.info(f"âœ… æ–‡æ¡£å·²æ·»åŠ : {filename} (åˆ†ç±»: {category})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def delete_document(self, filename: str) -> bool:
        """åˆ é™¤æ–‡æ¡£"""
        try:
            file_path = self.unified_root / filename
            
            # åˆ é™¤æ–‡ä»¶
            if file_path.exists():
                file_path.unlink()
            
            # ä»å…ƒæ•°æ®ç§»é™¤
            self._metadata['documents'] = [
                d for d in self._metadata['documents'] 
                if d['filename'] != filename
            ]
            
            # æ›´æ–°ç»Ÿè®¡
            categories = set(d.get('category', 'general') for d in self._metadata['documents'])
            self._metadata['stats'] = {
                "total_documents": len(self._metadata['documents']),
                "categories": list(categories),
                "last_updated": datetime.now().isoformat()
            }
            
            self._save_metadata()
            
            # æ¸…é™¤ç¼“å­˜
            if filename in self._cache:
                del self._cache[filename]
            
            logger.info(f"âœ… æ–‡æ¡£å·²åˆ é™¤: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        return self._metadata.get('stats', {
            "total_documents": 0,
            "categories": []
        })


# å…¨å±€å®ä¾‹ï¼ˆç±»ä¼¼åŸæ¥çš„ get_knowledge_loaderï¼‰
_unified_loader: Optional[UnifiedKnowledgeLoader] = None


def get_unified_knowledge_loader(kb_root: str = "/app/data/knowledge_bases") -> UnifiedKnowledgeLoader:
    """è·å–ç»Ÿä¸€çŸ¥è¯†åº“åŠ è½½å™¨å…¨å±€å®ä¾‹"""
    global _unified_loader
    if _unified_loader is None:
        _unified_loader = UnifiedKnowledgeLoader(kb_root)
    return _unified_loader
